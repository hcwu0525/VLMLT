{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.29s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import tqdm\n",
    "import torch\n",
    "import argparse\n",
    "import datetime\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "# from peft import PeftModel\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "from typing import Dict, Sequence, Optional,List\n",
    "# from accelerate import PartialState,Accelerator\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "import threading\n",
    "\n",
    "# from mhr.alignment.models.llava_v1_5.llava.utils import disable_torch_init\n",
    "# from mhr.alignment.models.llava_v1_5.llava.model.builder import load_pretrained_model\n",
    "# from mhr.alignment.models.llava_v1_5.llava.conversation import conv_templates, SeparatorStyle\n",
    "# from mhr.alignment.models.llava_v1_5.llava.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN, IGNORE_INDEX\n",
    "# from mhr.alignment.models.llava_v1_5.llava.mm_utils import process_images, tokenizer_image_token, get_model_name_from_path, KeywordsStoppingCriteria\n",
    "\n",
    "from llava.mm_utils import process_images, tokenizer_image_token, get_model_name_from_path, KeywordsStoppingCriteria\n",
    "from llava.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN, IGNORE_INDEX\n",
    "from llava.conversation import conv_templates, SeparatorStyle\n",
    "from llava.utils import disable_torch_init\n",
    "from llava.model.builder import load_pretrained_model\n",
    "from transformers import HfArgumentParser\n",
    "\n",
    "def initialize_model(model_path, device='cuda', peft_model_path=None):\n",
    "    model_name = get_model_name_from_path(model_path)\n",
    "    tokenizer, model, image_processor, context_len = load_pretrained_model(\n",
    "                model_path=model_path, \n",
    "                model_base=None, \n",
    "                model_name=model_name,\n",
    "                load_8bit=False, \n",
    "                load_4bit=False, \n",
    "                device=device,\n",
    "            )\n",
    "    if peft_model_path:\n",
    "        model = PeftModel.from_pretrained(model, peft_model_path, adapter_name=\"dpo\")\n",
    "        print(\"peft model loaded\")\n",
    "    model.to(torch.float16)\n",
    "    return tokenizer, model, image_processor, context_len\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(inp)\n",
    "model_path = \"/mnt/petrelfs/songmingyang/songmingyang/model/others/llava-v1.5-13b\"\n",
    "tokenizer, model, image_processor, context_len = initialize_model(model_path, device=\"cuda\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path = \"/mnt/petrelfs/songmingyang/code/mm/robustLMM/robustlmm/model_inference/llava_infer/samples/test1.jpg\"\n",
    "image_path = \"/mnt/petrelfs/songmingyang/songmingyang/data/mm/imgs/llava_aug/controlaug/000000000595_aug.jpg\"\n",
    "inp = \"Please Describe this image in detail\"\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "image_tensor = process_images([image], image_processor, model.config).to(model.dtype).to(model.device)\n",
    "\n",
    "conv_mode = \"llava_v1\"\n",
    "conv = conv_templates[conv_mode].copy()\n",
    "inp = inp.strip().replace('\\n', ' ').replace(DEFAULT_IMAGE_TOKEN, '').replace(DEFAULT_IM_START_TOKEN, '').replace(DEFAULT_IM_END_TOKEN, '').replace(\"<image>\",\"\")\n",
    "assert DEFAULT_IMAGE_TOKEN not in inp\n",
    "assert image is not None\n",
    "\n",
    "if image is not None and DEFAULT_IMAGE_TOKEN not in inp:\n",
    "    # first message\n",
    "    if model.config.mm_use_im_start_end:\n",
    "        inp = DEFAULT_IM_START_TOKEN + DEFAULT_IMAGE_TOKEN + DEFAULT_IM_END_TOKEN + '\\n' + inp\n",
    "    else:\n",
    "        inp = DEFAULT_IMAGE_TOKEN + '\\n' + inp\n",
    "    conv.append_message(conv.roles[0], inp)\n",
    "    image = None\n",
    "else:\n",
    "    # later messages\n",
    "    conv.append_message(conv.roles[0], inp)\n",
    "conv.append_message(conv.roles[1], None)\n",
    "prompt = conv.get_prompt()\n",
    "assert prompt.count(DEFAULT_IMAGE_TOKEN) == 1\n",
    "assert prompt.count(DEFAULT_IM_START_TOKEN) == 0\n",
    "# assert prompt.count(\"\\n\") == 0\n",
    "\n",
    "input_ids = tokenizer_image_token(prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors='pt').unsqueeze(0).to(model.device)\n",
    "\n",
    "\n",
    "generation_num=1\n",
    "stop_str = conv.sep if conv.sep_style != SeparatorStyle.TWO else conv.sep2\n",
    "keywords = [stop_str]   \n",
    "    \n",
    "\n",
    "\n",
    "stopping_criteria = KeywordsStoppingCriteria(keywords, tokenizer, input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/petrelfs/songmingyang/anaconda3/envs/smoe/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "        output_ids = model.generate(\n",
    "                inputs=input_ids,\n",
    "                images=image_tensor,\n",
    "                do_sample=False,\n",
    "                temperature=0,\n",
    "                max_new_tokens=512,\n",
    "                use_cache=True,\n",
    "                stopping_criteria=[stopping_criteria],\n",
    "        )\n",
    "    # output_ids = self.model.generate(\n",
    "    #                     inputs=input_ids,\n",
    "    #                     images=image_tensors,\n",
    "    #                     do_sample=False,\n",
    "    #                     temperature=0,\n",
    "    #                     max_new_tokens=512,\n",
    "    #                     use_cache=True,\n",
    "    #                     stopping_criteria=[stopping_criteria],\n",
    "    #                     )\n",
    "        outputs = tokenizer.batch_decode(output_ids, skip_special_tokens=True)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The image features a graph displaying sales data for a company over a period of time. The graph shows a steady increase in sales, with the sales numbers rising from 2009 to 2012. The sales data is presented in a clear and organized manner, making it easy to understand the trend. The graph is predominantly blue, with the sales numbers represented by various shades of blue, ranging from light to dark. The overall trend of the graph indicates a positive growth in sales for the company.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-01-31 02:58:43 60069:60069 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "/mnt/petrelfs/songmingyang/anaconda3/envs/smoe/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "STAGE:2025-01-31 02:59:02 60069:60069 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2025-01-31 02:59:03 60069:60069 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "with torch.profiler.profile(\n",
    "    activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "    with_flops=True,  # 启用 FLOPs 统计\n",
    "    record_shapes=True,\n",
    "    with_stack=True\n",
    ") as prof:\n",
    "     output_ids = model.generate(\n",
    "                inputs=input_ids,\n",
    "                images=image_tensor,\n",
    "                do_sample=False,\n",
    "                temperature=0,\n",
    "                max_new_tokens=512,\n",
    "                use_cache=True,\n",
    "                stopping_criteria=[stopping_criteria],\n",
    "        )\n",
    "total_flops = sum(event.flops for event in prof.key_averages() if event.flops is not None)\n",
    "print(f\"Total FLOPs: {convert_to_human_readable_size(total_flops)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_human_readable_size(num):\n",
    "    if num / 1e27 > 1:\n",
    "        return f\"{num / 1e27:.2f} R\"\n",
    "    elif num / 1e24 > 1:\n",
    "        return f\"{num / 1e24:.2f} Y\"\n",
    "    elif num / 1e21 > 1:\n",
    "        return f\"{num / 1e21:.2f} Z\"\n",
    "    elif num / 1e18 > 1:\n",
    "        return f\"{num / 1e18:.2f} E\"\n",
    "    elif num / 1e15 > 1:\n",
    "        return f\"{num / 1e15:.2f} P\"\n",
    "    elif num / 1e12 > 1:\n",
    "        return f\"{num / 1e12:.2f} T\"\n",
    "    elif num / 1e9 > 1:\n",
    "        return f\"{num / 1e9:.2f} B\"\n",
    "    elif num / 1e6 > 1:\n",
    "        return f\"{num / 1e6:.2f} M\"\n",
    "    elif num / 1e3 > 1:\n",
    "        return f\"{num / 1e3:.2f} K\"\n",
    "    else:\n",
    "        return f\"{num}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total FLOPs: 19.83 T\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Total FLOPs: {convert_to_human_readable_size(total_flops)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real flops:1.66 E\n"
     ]
    }
   ],
   "source": [
    "balance = 581745\n",
    "aug = 665298\n",
    "real_flops =  total_flops * (aug-balance)\n",
    "print(f\"real flops:{convert_to_human_readable_size(real_flops)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real flops:1.55 E\n"
     ]
    }
   ],
   "source": [
    "balance = 1168639\n",
    "aug = 1246901\n",
    "real_flops =  total_flops * (aug-balance)\n",
    "print(f\"real flops:{convert_to_human_readable_size(real_flops)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smoe",
   "language": "python",
   "name": "smoe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
