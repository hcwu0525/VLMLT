{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mhr.utils.utils import process_jsonl\n",
    "\n",
    "\n",
    "high_resource=\"en ru de zh ja fr es pt\".split()\n",
    "low_resource=\"uk bg tr ar ko\".split()\n",
    "languages = high_resource + low_resource\n",
    "metric_list=[\"CHAIR\", \"Cover\", \"Cog\", \"Ha_p\", \"Language_Qualified\"]\n",
    "metric_dict={\n",
    "    \"CHAIR\":dict(large_is_better=False),\n",
    "    \"Cover\":dict(large_is_better=True),\n",
    "    \"Cog\":dict(large_is_better=False),\n",
    "    \"Ha_p\":dict(large_is_better=False),\n",
    "    \"Language_Qualified\":dict(large_is_better=True),\n",
    "}\n",
    "model_dict={\n",
    "    \"LLaVA Baseline\":dict(\n",
    "        file_path=\"/mnt/petrelfs/songmingyang/code/tools/lmms-eval/lmms_eval/other_evals/AMBER/model_inference/scripts/eval/origin_amber_result.jsonl\",\n",
    "        start_str=f\"& Baseline \",\n",
    "        metric_log={a:[] for a in metric_list}\n",
    "        \n",
    "        \n",
    "    ),\n",
    "    \"LLaVA Ours\":dict(\n",
    "        file_path=\"/mnt/petrelfs/songmingyang/code/tools/lmms-eval/lmms_eval/other_evals/AMBER/model_inference/scripts/eval/ours_amber_result.jsonl\",\n",
    "        start_str=f\"& Ours \",\n",
    "        metric_log={a:[] for a in metric_list}\n",
    "        \n",
    "    ),\n",
    "    \n",
    "}\n",
    "model_num = len(model_dict)\n",
    "for model,model_item in  model_dict.items():\n",
    "    model_item[\"result\"] = process_jsonl(model_item[\"file_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow{2}{*}{\\centering \\textbf{en}}& Baseline & 4.0& 34.3& 0.6& 8.4& \\textbf{100.0}\\\\\n",
      "& Ours & \\textbf{3.1}& \\textbf{34.5}& \\textbf{0.4}& \\textbf{6.6}& \\textbf{100.0}\\\\\n",
      "\\hline\n",
      "\\multirow{2}{*}{\\centering \\textbf{ru}}& Baseline & \\textbf{0.0}& 0.1& \\textbf{0.0}& \\textbf{0.0}& 0.5\\\\\n",
      "& Ours & 10.2& \\textbf{4.4}& 0.2& 2.9& \\textbf{100.0}\\\\\n",
      "\\hline\n",
      "\\multirow{2}{*}{\\centering \\textbf{de}}& Baseline & \\textbf{0.0}& 0.0& \\textbf{0.0}& \\textbf{0.0}& 0.0\\\\\n",
      "& Ours & 5.3& \\textbf{23.3}& 0.7& 8.1& \\textbf{99.8}\\\\\n",
      "\\hline\n",
      "\\multirow{2}{*}{\\centering \\textbf{zh}}& Baseline & 59.9& 1.4& \\textbf{0.0}& \\textbf{1.4}& 9.7\\\\\n",
      "& Ours & \\textbf{7.0}& \\textbf{23.5}& 0.5& 11.1& \\textbf{99.9}\\\\\n",
      "\\hline\n",
      "\\multirow{2}{*}{\\centering \\textbf{ja}}& Baseline & 12.3& 14.9& 0.9& \\textbf{12.2}& 91.0\\\\\n",
      "& Ours & \\textbf{10.8}& \\textbf{20.4}& \\textbf{0.8}& 13.9& \\textbf{100.0}\\\\\n",
      "\\hline\n",
      "\\multirow{2}{*}{\\centering \\textbf{fr}}& Baseline & \\textbf{0.0}& 0.0& \\textbf{0.0}& \\textbf{0.0}& 0.0\\\\\n",
      "& Ours & 9.1& \\textbf{30.5}& 1.5& 18.4& \\textbf{100.0}\\\\\n",
      "\\hline\n",
      "\\multirow{2}{*}{\\centering \\textbf{es}}& Baseline & 83.9& 0.2& \\textbf{0.0}& \\textbf{6.7}& 0.1\\\\\n",
      "& Ours & \\textbf{7.3}& \\textbf{29.0}& 0.9& 12.4& \\textbf{99.9}\\\\\n",
      "\\hline\n",
      "\\multirow{2}{*}{\\centering \\textbf{pt}}& Baseline & \\textbf{7.9}& 1.3& \\textbf{0.1}& \\textbf{0.5}& 3.0\\\\\n",
      "& Ours & 10.6& \\textbf{27.8}& 2.2& 18.3& \\textbf{100.0}\\\\\n",
      "\\hline\n",
      "\\multirow{2}{*}{\\centering \\textbf{Avg$^\\text{H}$.}}& \\rowcolor{gray!20}  Baseline & 21.0& 6.5& \\textbf{0.2}& \\textbf{3.6}& 25.5\\\\\n",
      "& \\rowcolor{gray!20}  Ours & \\textbf{7.9}& \\textbf{24.2}& 0.9& 11.5& \\textbf{100.0}\\\\\n",
      "\\hline\n",
      "\\multirow{2}{*}{\\centering \\textbf{uk}}& Baseline & \\textbf{5.6}& 6.4& \\textbf{0.2}& \\textbf{2.1}& 70.3\\\\\n",
      "& Ours & 7.9& \\textbf{8.4}& 0.3& 4.1& \\textbf{99.9}\\\\\n",
      "\\hline\n",
      "\\multirow{2}{*}{\\centering \\textbf{bg}}& Baseline & 50.0& 0.0& \\textbf{0.0}& \\textbf{0.1}& 0.2\\\\\n",
      "& Ours & \\textbf{9.2}& \\textbf{8.9}& 1.0& 5.3& \\textbf{75.5}\\\\\n",
      "\\hline\n",
      "\\multirow{2}{*}{\\centering \\textbf{tr}}& Baseline & 74.4& 0.5& \\textbf{0.2}& \\textbf{8.6}& 6.8\\\\\n",
      "& Ours & \\textbf{46.4}& \\textbf{5.0}& 0.5& 9.9& \\textbf{58.1}\\\\\n",
      "\\hline\n",
      "\\multirow{2}{*}{\\centering \\textbf{ar}}& Baseline & 33.6& 10.3& \\textbf{1.2}& \\textbf{21.8}& 80.7\\\\\n",
      "& Ours & \\textbf{26.5}& \\textbf{20.4}& 2.1& 30.9& \\textbf{100.0}\\\\\n",
      "\\hline\n",
      "\\multirow{2}{*}{\\centering \\textbf{ko}}& Baseline & 99.9& 0.0& \\textbf{0.0}& \\textbf{0.1}& 0.6\\\\\n",
      "& Ours & \\textbf{21.4}& \\textbf{6.9}& 0.8& 8.5& \\textbf{100.0}\\\\\n",
      "\\hline\n",
      "\\multirow{2}{*}{\\centering \\textbf{Avg$^\\text{L}$.}}& \\rowcolor{gray!20}  Baseline & 52.7& 3.4& \\textbf{0.3}& \\textbf{6.5}& 31.7\\\\\n",
      "& \\rowcolor{gray!20}  Ours & \\textbf{22.3}& \\textbf{9.9}& 0.9& 11.7& \\textbf{86.7}\\\\\n",
      "\\hline\n",
      "\\multirow{2}{*}{\\centering \\textbf{Avg$^\\text{A}$.}}& \\rowcolor{gray!20}  Baseline & 33.2& 5.3& \\textbf{0.2}& \\textbf{4.8}& 27.9\\\\\n",
      "& \\rowcolor{gray!20}  Ours & \\textbf{13.4}& \\textbf{18.7}& 0.9& 11.6& \\textbf{94.9}\\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = \"\"\n",
    "metric_log = {model:{metric:[] for metric in metric_dict.keys()} for model in model_dict.keys()}\n",
    "for lang_idx,lang in enumerate(high_resource):\n",
    "    compare_list = {metric:[model_item[\"result\"][lang_idx][metric] for _,model_item in model_dict.items()] for metric in metric_dict.keys()}\n",
    "    lang_begin_str = f\"\\multirow{{{len(model_dict)}}}{{*}}{{\\\\centering \\\\textbf{{{lang}}}}}\"\n",
    "    res += lang_begin_str\n",
    "    for model,model_item in model_dict.items():\n",
    "        model_res = model_item[\"start_str\"]\n",
    "        assert lang == model_item[\"result\"][lang_idx][\"language\"] ,f\"lang:{lang}, res_lang:{model_item['result'][lang_idx]['language']} ,{lang_idx}\"\n",
    "        for metric in metric_list:\n",
    "            num_res = model_item[\"result\"][lang_idx][metric]\n",
    "            metric_log[model][metric].append(num_res)\n",
    "            if num_res == max(compare_list[metric]) and metric_dict[metric][\"large_is_better\"]:\n",
    "                model_res += f\"& \\\\textbf{{{num_res:.1f}}}\"\n",
    "            elif num_res == min(compare_list[metric]) and not metric_dict[metric][\"large_is_better\"]:\n",
    "                model_res += f\"& \\\\textbf{{{num_res:.1f}}}\"\n",
    "            else:\n",
    "                model_res += f\"& {num_res:.1f}\"\n",
    "        model_res += \"\\\\\\\\\\n\"\n",
    "        res += model_res\n",
    "    res += \"\\hline\\n\"\n",
    "\n",
    "avg_begin_str = f\"\\multirow{{{len(model_dict)}}}{{*}}{{\\\\centering \\\\textbf{{Avg$^\\\\text{{H}}$.}}}}\"\n",
    "res += avg_begin_str\n",
    "avg_compare_dict = {metric:[sum(metric_log[model][metric])/len(metric_log[model][metric]) for model in model_dict.keys()] for metric in metric_dict.keys()}\n",
    "for model,model_item in model_dict.items():\n",
    "    model_res = model_item[\"start_str\"].split(\"&\")[-1]\n",
    "    model_res = f\"& \\\\rowcolor{{gray!20}} \"+model_res\n",
    "    for metric in metric_list:\n",
    "        num_res = sum(metric_log[model][metric])/len(metric_log[model][metric])\n",
    "        if num_res == max(avg_compare_dict[metric]) and metric_dict[metric][\"large_is_better\"]:\n",
    "            model_res += f\"& \\\\textbf{{{num_res:.1f}}}\"\n",
    "        elif num_res == min(avg_compare_dict[metric]) and not metric_dict[metric][\"large_is_better\"]:\n",
    "            model_res += f\"& \\\\textbf{{{num_res:.1f}}}\"\n",
    "        else:\n",
    "            model_res += f\"& {num_res:.1f}\"\n",
    "    model_res += \"\\\\\\\\\\n\"\n",
    "    res += model_res\n",
    "res += \"\\hline\\n\"\n",
    "    \n",
    "    \n",
    "metric_log = {model:{metric:[] for metric in metric_dict.keys()} for model in model_dict.keys()}\n",
    "for lang_idx,lang in enumerate(low_resource):\n",
    "    \n",
    "    lang_idx+=len(high_resource)\n",
    "    compare_list = {metric:[model_item[\"result\"][lang_idx][metric] for _,model_item in model_dict.items()] for metric in metric_dict.keys()}\n",
    "    lang_begin_str = f\"\\multirow{{{len(model_dict)}}}{{*}}{{\\\\centering \\\\textbf{{{lang}}}}}\"\n",
    "    res += lang_begin_str\n",
    "    for model,model_item in model_dict.items():\n",
    "        model_res = model_item[\"start_str\"]\n",
    "        assert lang == model_item[\"result\"][lang_idx][\"language\"] ,f\"lang:{lang}, res_lang:{model_item['result'][lang_idx]['language']}\"\n",
    "        for metric in metric_list:\n",
    "            num_res = model_item[\"result\"][lang_idx][metric]\n",
    "            metric_log[model][metric].append(num_res)\n",
    "            if num_res == max(compare_list[metric]) and metric_dict[metric][\"large_is_better\"]:\n",
    "                model_res += f\"& \\\\textbf{{{num_res:.1f}}}\"\n",
    "            elif num_res == min(compare_list[metric]) and not metric_dict[metric][\"large_is_better\"]:\n",
    "                model_res += f\"& \\\\textbf{{{num_res:.1f}}}\"\n",
    "            else:\n",
    "                model_res += f\"& {num_res:.1f}\"\n",
    "        model_res += \"\\\\\\\\\\n\"\n",
    "        res += model_res \n",
    "    res += \"\\hline\\n\"\n",
    "\n",
    "avg_begin_str = f\"\\multirow{{{len(model_dict)}}}{{*}}{{\\\\centering \\\\textbf{{Avg$^\\\\text{{L}}$.}}}}\"\n",
    "res += avg_begin_str\n",
    "avg_compare_dict = {metric:[sum(metric_log[model][metric])/len(metric_log[model][metric]) for model in model_dict.keys()] for metric in metric_dict.keys()}\n",
    "for model,model_item in model_dict.items():\n",
    "    model_res = model_item[\"start_str\"].split(\"&\")[-1]\n",
    "    model_res = f\"& \\\\rowcolor{{gray!20}} \"+model_res\n",
    "    for metric in metric_list:\n",
    "        num_res = sum(metric_log[model][metric])/len(metric_log[model][metric])\n",
    "        if num_res == max(avg_compare_dict[metric]) and metric_dict[metric][\"large_is_better\"]:\n",
    "            model_res += f\"& \\\\textbf{{{num_res:.1f}}}\"\n",
    "        elif num_res == min(avg_compare_dict[metric]) and not metric_dict[metric][\"large_is_better\"]:\n",
    "            model_res += f\"& \\\\textbf{{{num_res:.1f}}}\"\n",
    "        else:\n",
    "            model_res += f\"& {num_res:.1f}\"\n",
    "    model_res += \"\\\\\\\\\\n\"\n",
    "    res += model_res\n",
    "res += \"\\hline\\n\"\n",
    "\n",
    "\n",
    "avg_dict = {model:[[model_dict[model][\"result\"][lang_idx][metric] for lang_idx in range(len(languages))] for metric in metric_list]  for model in model_dict.keys()}\n",
    "for avg_model,avg_model_item in avg_dict.items():\n",
    "    avg_model_item = [sum(avg_model_item[metric_idx])/len(avg_model_item[metric_idx]) for metric_idx in range(len(avg_model_item))]\n",
    "    avg_dict[avg_model] = avg_model_item\n",
    "avg_begin_str = f\"\\multirow{{{len(model_dict)}}}{{*}}{{\\\\centering \\\\textbf{{Avg$^\\\\text{{A}}$.}}}}\"\n",
    "res += avg_begin_str\n",
    "avg_conmpare_dict = {metric:[avg_dict[model][metric_list.index(metric)] for model in model_dict.keys()] for metric in metric_dict.keys()}\n",
    "for model,model_item in model_dict.items():\n",
    "    model_res = model_item[\"start_str\"].split(\"&\")[-1]\n",
    "    model_res = f\"& \\\\rowcolor{{gray!20}} \"+model_res\n",
    "    for metric in metric_list:\n",
    "        num_res = avg_dict[model][metric_list.index(metric)]\n",
    "        if num_res == max(avg_conmpare_dict[metric]) and metric_dict[metric][\"large_is_better\"]:\n",
    "            model_res += f\"& \\\\textbf{{{num_res:.1f}}}\"\n",
    "        elif num_res == min(avg_conmpare_dict[metric]) and not metric_dict[metric][\"large_is_better\"]:\n",
    "            model_res += f\"& \\\\textbf{{{num_res:.1f}}}\"\n",
    "        else:\n",
    "            model_res += f\"& {num_res:.1f}\"\n",
    "    model_res += \"\\\\\\\\\\n\"\n",
    "    res += model_res\n",
    "\n",
    "\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smoe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
