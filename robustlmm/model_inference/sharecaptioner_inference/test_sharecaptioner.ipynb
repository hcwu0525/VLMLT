{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/petrelfs/songmingyang/anaconda3/envs/smoe/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "sentencepiece_processor.cc(922) LOG(ERROR) src/sentencepiece_processor.cc(289) [model_] Model is not initialized.\n",
      "Returns default value 0\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set max length to 20\n",
      "Init VIT ... Position interpolate from 16x16 to 32x32\n",
      "Done\n",
      "Init Perceive Sampler ... Done\n",
      "Init InternLM ... Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.36s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "model_id=\"/mnt/petrelfs/songmingyang/songmingyang/model/mm/ShareCaptioner\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(model_id, trust_remote_code=True)\n",
    "model.tokenizer = tokenizer\n",
    "model=model.to(\"cuda\").to(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor \n",
    "from PIL import Image \n",
    "train_png=\"/mnt/petrelfs/songmingyang/code/mm/robustLMM/robustlmm/data_adjustment/diffusion_augment/train.jpg\"\n",
    "img = Image.open(train_png).convert('RGB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=4\n",
    "img_embed=model.vis_processor(img).unsqueeze(0).to(model.dtype).to(model.device)\n",
    "img_embed=img_embed.repeat(batch_size,1,1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 448, 448])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg1 = '<|User|>:'\n",
    "seg2 = f'Analyze the image in a comprehensive and detailed manner.{model.eoh}\\n<|Bot|>:'\n",
    "seg_emb1 = model.encode_text(seg1, add_special_tokens=True)\n",
    "seg_emb2 = model.encode_text(seg2, add_special_tokens=False)\n",
    "tmp_seg_emb1 = seg_emb1.repeat(batch_size, 1, 1).to(model.device).to(model.dtype)\n",
    "tmp_seg_emb2 = seg_emb2.repeat(batch_size, 1, 1).to(model.device).to(model.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_embed = model.encode_img(img_embed)\n",
    "input_emb = torch.cat([tmp_seg_emb1, img_embed, tmp_seg_emb2], dim=1)\n",
    "out_embeds = model.internlm_model.generate(inputs_embeds=input_emb,\n",
    "                                           max_length=800,\n",
    "                                           num_beams=3,\n",
    "                                           min_length=1,\n",
    "                                           do_sample=True,\n",
    "                                           repetition_penalty=1.5,\n",
    "                                           length_penalty=1.0,\n",
    "                                           temperature=1.,\n",
    "                                           eos_token_id=model.tokenizer.eos_token_id,\n",
    "                                           num_return_sequences=1,\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_embeds[out_embeds == -1] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rid_of_substr(substr,list_of_target_str):\n",
    "    renewed_target = []\n",
    "    for temp_str in list_of_target_str:\n",
    "        for temp_sub in substr:\n",
    "            temp_str = temp_str.replace(temp_sub,\"\")\n",
    "        renewed_target.append(temp_str)\n",
    "    return renewed_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_text = tokenizer.batch_decode(out_embeds, skip_special_tokens=True)\n",
    "get_rid_strs = [\"<s>\",\"</s>\",\"<TOKENS_UNUSED_1>\",\"<unk>\"]\n",
    "out_text = get_rid_of_substr(get_rid_strs,out_text)\n",
    "# out_text = model.decode_text(out_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<s>',\n",
       " 'eos_token': '</s>',\n",
       " 'unk_token': '<unk>',\n",
       " 'pad_token': '</s>'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"  The image captures a bustling scene at a train station. Dominating the frame are three trains, each with its own distinct color scheme and purpose. \\n\\nOn the left, a green and yellow passenger train is in motion, its multiple cars filled with unseen passengers. The middle of the image is dominated by a red and white freight train, a testament to the industrial nature of the scene. It's stationary, perhaps waiting for its cargo to be loaded or unloaded.\\n\\nOn the right, a green and yellow passenger train mirrors its counterpart on the left, suggesting a symmetrical balance in the composition of the image. \\n\\nThe trains are situated on multiple tracks that crisscross and diverge, creating a complex network of steel and iron. Overhead wires stretch across the scene, hinting at the electric power that propels these mechanical beasts.\\n\\nIn the background, a bridge and trees can be seen, adding a touch of nature to this industrial landscape. The bridge, possibly a vital link for the trains, and the trees, providing a contrast to the man-made structures.\\n\\nOverall, the image is a snapshot of a moment in the life of a busy train station, where human-made machines and nature coexist.\\n\",\n",
       " \"  The image captures a bustling train yard, teeming with a multitude of trains. The trains, painted in vibrant hues of red, green, and yellow, add a splash of color to the otherwise industrial setting. The perspective of the image is from an elevated position, providing a bird's eye view of the yard. This vantage point allows us to see the intricate network of tracks that crisscross the yard, guiding the trains on their paths. The background is a blend of nature and infrastructure, with trees interspersed among the tracks and buildings peeking through the foliage.\\n\",\n",
       " \"  The image captures a bustling train yard, teeming with the energy of urban transportation. Dominating the scene are multiple trains, their colors a vibrant mix of red, green, and yellow, adding a splash of color to the industrial landscape. The trains, varying in size and number, are stationed on the tracks, ready to embark on their respective journeys.\\n\\nThe perspective of the image is from an elevated position, providing a bird's eye view of the yard. This vantage point allows for a comprehensive view of the yard, revealing the intricate network of tracks that crisscross and overlap, guiding the trains on their paths.\\n\\nIn the background, power lines stretch across the scene, a testament to human ingenuity in harnessing energy for transportation. Despite the absence of any human figures, the image is imbued with a sense of activity and purpose, a snapshot of a moment in the ceaseless rhythm of city life.\\n\",\n",
       " \"  The image captures a bustling scene at a train station. Dominating the frame are multiple trains, each with its own distinct color scheme. On the left, a green and yellow passenger train is stationed, ready to embark on its journey. In the center, a red and white freight train stands, perhaps loaded with goods for transport. To the right, another green and yellow passenger train mirrors its counterpart on the left, adding to the symmetry of the scene.\\n\\nThe trains are parked on tracks that crisscross and diverge, creating a complex network of steel lines against the backdrop of the station. Overhead wires stretch across the image, hinting at the electric power that propels these mechanical beasts.\\n\\nThe station itself is nestled amidst nature, with trees and bushes peeking into the frame from the sides, providing a touch of greenery to the industrial landscape. Despite the absence of any discernible text or human figures, the image speaks volumes about the rhythm and routine of life at a train station. It's a snapshot of a moment, frozen in time, yet brimming with stories waiting to be told.\\n\"]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"Analyze the image in a comprehensive and detailed manner.\"\n",
    "output_embeds = model.generate(text=prompt,image=train_png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' <s> The image captures a bustling scene at a train station. Dominating the frame are three trains, each with its own distinct color scheme. The first train, painted in vibrant hues of red and green, is moving towards the right side of the image. The second train, adorned in shades of green and yellow, is heading in the opposite direction, towards the left side of the image. The third train, mirroring the first with its red and green color scheme, is stationary, adding a sense of balance to the scene.\\n\\nThe trains are situated on multiple tracks that crisscross each other, creating a complex network of steel and iron. Overhead wires stretch across the image, hinting at the electric power that propels these mechanical beasts.\\n\\nIn the background, a bridge and trees can be seen, providing a stark contrast to the industrial nature of the train station. The bridge, with its sturdy construction, stands as a testament to human ingenuity, while the trees add a touch of nature to the otherwise man-made landscape.\\n\\nDespite the absence of any discernible text or human figures, the image is rich in detail and activity, painting a vivid picture of a day in the life of a busy train station. The precise locations of the objects and their relative positions to each other contribute to the overall composition of the image, creating a dynamic yet harmonious scene.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg2 = f'Analyze the image in a comprehensive and detailed manner.{model.eoh}\\n<|Bot|>:'\n",
    "seg_emb2 = model.encode_text(seg2, add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 18, 4096])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 258, 4096])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smoe",
   "language": "python",
   "name": "smoe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
